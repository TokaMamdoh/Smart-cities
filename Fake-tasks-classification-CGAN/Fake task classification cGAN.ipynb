{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Importing Libraries"
      ],
      "metadata": {
        "id": "WNkMkyQhTGwV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_-7HuGvFSsXj"
      },
      "outputs": [],
      "source": [
        "# Essential libraries\n",
        "import numpy as np \n",
        "import pandas as pd \n",
        "import matplotlib.pyplot as plt \n",
        "\n",
        "# Sklearn libraries\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "\n",
        "# Tensorflow libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from tensorflow.keras import layers\n",
        "from keras.layers import InputLayer, Dense, Dropout,BatchNormalization\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from tensorflow.keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing the dateset"
      ],
      "metadata": {
        "id": "GwNW4LsWTmFD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('/content/MCSDatasetNEXTCONLab.csv')\n",
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "sGeSehvjTk7z",
        "outputId": "75aebd48-5a46-4ee4-f04c-341236efc2a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   ID   Latitude  Longitude  Day  Hour  Minute  Duration  RemainingTime  \\\n",
              "0   1  45.442142 -75.303369    1     4      13        40             40   \n",
              "1   1  45.442154 -75.304366    1     4      23        40             30   \n",
              "2   1  45.442104 -75.303963    1     4      33        40             20   \n",
              "3   1  45.441868 -75.303577    1     4      43        40             10   \n",
              "4   2  45.447727 -75.147722    2    15      49        30             30   \n",
              "\n",
              "   Resources  Coverage  OnPeakHours  GridNumber  Ligitimacy  \n",
              "0          9        91            0      131380           1  \n",
              "1          9        91            0      131380           1  \n",
              "2          9        91            0      121996           1  \n",
              "3          9        91            0      121996           1  \n",
              "4          5        47            0      140784           1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f1223543-9a32-4ab8-bb91-10797ff35d2e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Latitude</th>\n",
              "      <th>Longitude</th>\n",
              "      <th>Day</th>\n",
              "      <th>Hour</th>\n",
              "      <th>Minute</th>\n",
              "      <th>Duration</th>\n",
              "      <th>RemainingTime</th>\n",
              "      <th>Resources</th>\n",
              "      <th>Coverage</th>\n",
              "      <th>OnPeakHours</th>\n",
              "      <th>GridNumber</th>\n",
              "      <th>Ligitimacy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>45.442142</td>\n",
              "      <td>-75.303369</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>13</td>\n",
              "      <td>40</td>\n",
              "      <td>40</td>\n",
              "      <td>9</td>\n",
              "      <td>91</td>\n",
              "      <td>0</td>\n",
              "      <td>131380</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>45.442154</td>\n",
              "      <td>-75.304366</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>23</td>\n",
              "      <td>40</td>\n",
              "      <td>30</td>\n",
              "      <td>9</td>\n",
              "      <td>91</td>\n",
              "      <td>0</td>\n",
              "      <td>131380</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>45.442104</td>\n",
              "      <td>-75.303963</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>33</td>\n",
              "      <td>40</td>\n",
              "      <td>20</td>\n",
              "      <td>9</td>\n",
              "      <td>91</td>\n",
              "      <td>0</td>\n",
              "      <td>121996</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>45.441868</td>\n",
              "      <td>-75.303577</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>43</td>\n",
              "      <td>40</td>\n",
              "      <td>10</td>\n",
              "      <td>9</td>\n",
              "      <td>91</td>\n",
              "      <td>0</td>\n",
              "      <td>121996</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>45.447727</td>\n",
              "      <td>-75.147722</td>\n",
              "      <td>2</td>\n",
              "      <td>15</td>\n",
              "      <td>49</td>\n",
              "      <td>30</td>\n",
              "      <td>30</td>\n",
              "      <td>5</td>\n",
              "      <td>47</td>\n",
              "      <td>0</td>\n",
              "      <td>140784</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f1223543-9a32-4ab8-bb91-10797ff35d2e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f1223543-9a32-4ab8-bb91-10797ff35d2e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f1223543-9a32-4ab8-bb91-10797ff35d2e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting the dataset into inputs and outputs\n",
        "x = data.iloc[:,:-1].values\n",
        "y = data.iloc[:,-1].values\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_cl1wSisUAoh",
        "outputId": "68852e5b-978a-4d7d-e318-2b749ddc11f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1.00000000e+00,  4.54421419e+01, -7.53033693e+01, ...,\n",
              "         9.10000000e+01,  0.00000000e+00,  1.31380000e+05],\n",
              "       [ 1.00000000e+00,  4.54421541e+01, -7.53043661e+01, ...,\n",
              "         9.10000000e+01,  0.00000000e+00,  1.31380000e+05],\n",
              "       [ 1.00000000e+00,  4.54421041e+01, -7.53039633e+01, ...,\n",
              "         9.10000000e+01,  0.00000000e+00,  1.21996000e+05],\n",
              "       ...,\n",
              "       [ 4.00000000e+03,  4.54366819e+01, -7.51524163e+01, ...,\n",
              "         6.30000000e+01,  0.00000000e+00,  1.22015000e+05],\n",
              "       [ 4.00000000e+03,  4.54369777e+01, -7.51532778e+01, ...,\n",
              "         6.30000000e+01,  0.00000000e+00,  1.22015000e+05],\n",
              "       [ 4.00000000e+03,  4.54369829e+01, -7.51532401e+01, ...,\n",
              "         6.30000000e+01,  0.00000000e+00,  1.22015000e+05]])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eEp4Q-4yUQKJ",
        "outputId": "17f567a2-43ba-46ff-80a4-fa80d2799a74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, ..., 1, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Splitting dataset into train and test sets"
      ],
      "metadata": {
        "id": "uLu9ehGaUTSA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size = 0.2, random_state = 0)\n",
        "print(x_train)\n",
        "print(x_test),\n",
        "print(y_train)\n",
        "print(y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0_laQ7UKUR12",
        "outputId": "81030273-25c7-4a11-e753-5239ae0dca8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 1.71000000e+02  4.54643174e+01 -7.52088358e+01 ...  8.00000000e+01\n",
            "   1.00000000e+00  1.68928000e+05]\n",
            " [ 2.33500000e+03  4.55283185e+01 -7.51242916e+01 ...  5.50000000e+01\n",
            "   0.00000000e+00  2.72162000e+05]\n",
            " [ 1.25700000e+03  4.54930959e+01 -7.52199227e+01 ...  5.70000000e+01\n",
            "   0.00000000e+00  2.15847000e+05]\n",
            " ...\n",
            " [ 2.73800000e+03  4.54682185e+01 -7.52736848e+01 ...  6.10000000e+01\n",
            "   0.00000000e+00  1.68920000e+05]\n",
            " [ 2.99600000e+03  4.54448243e+01 -7.52308821e+01 ...  4.40000000e+01\n",
            "   0.00000000e+00  1.31389000e+05]\n",
            " [ 7.44000000e+02  4.55425901e+01 -7.51854975e+01 ...  8.80000000e+01\n",
            "   0.00000000e+00  3.00307000e+05]]\n",
            "[[ 3.64600000e+03  4.55401162e+01 -7.51799010e+01 ...  6.50000000e+01\n",
            "   0.00000000e+00  3.00308000e+05]\n",
            " [ 3.60200000e+03  4.55174092e+01 -7.53040321e+01 ...  6.20000000e+01\n",
            "   0.00000000e+00  2.53372000e+05]\n",
            " [ 3.86000000e+03  4.55070362e+01 -7.52475136e+01 ...  7.90000000e+01\n",
            "   0.00000000e+00  2.34611000e+05]\n",
            " ...\n",
            " [ 4.50000000e+02  4.55517722e+01 -7.52773530e+01 ...  4.60000000e+01\n",
            "   0.00000000e+00  3.19063000e+05]\n",
            " [ 2.94700000e+03  4.55377989e+01 -7.51025611e+01 ...  7.60000000e+01\n",
            "   0.00000000e+00  2.90933000e+05]\n",
            " [ 6.22000000e+02  4.54061924e+01 -7.52354614e+01 ...  5.00000000e+01\n",
            "   1.00000000e+00  6.57010000e+04]]\n",
            "[1 1 1 ... 1 1 1]\n",
            "[1 1 1 ... 1 1 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Scaling"
      ],
      "metadata": {
        "id": "DzhwBgHZjXpO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sc = MinMaxScaler()\n",
        "x_train = sc.fit_transform(x_train)\n",
        "x_test = sc.transform(x_test)"
      ],
      "metadata": {
        "id": "TfBSJ2DOjW2Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modeling"
      ],
      "metadata": {
        "id": "Xdz4uUHYn-qc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Building function contains all classic machine learning model\n",
        "def model(x_train,y_train,x_test):\n",
        "  #Random Forest\n",
        "  RF = RandomForestClassifier(n_estimators=100,random_state =0)\n",
        "  RF.fit(x_train,y_train)\n",
        "  y_pred_RF = RF.predict(x_test)\n",
        "\n",
        "  # Naive bayes\n",
        "  NB = GaussianNB()\n",
        "  NB.fit(x_train,y_train)\n",
        "  y_pred_NB = NB.predict(x_test)\n",
        "\n",
        "  #Adaboost\n",
        "  Adaboost = AdaBoostClassifier(n_estimators = 100, random_state = 0)\n",
        "  Adaboost.fit(x_train,y_train)\n",
        "  y_pred_Adaboost = Adaboost.predict(x_test)\n",
        "\n",
        "  return y_pred_RF, y_pred_NB, y_pred_Adaboost,RF,NB,Adaboost"
      ],
      "metadata": {
        "id": "Py94QtPtoBDJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_RF, y_pred_NB,y_pred_Adaboost,RF,NB,Adaboost = model(x_train,y_train,x_test)"
      ],
      "metadata": {
        "id": "5wxtL4i2owWY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation"
      ],
      "metadata": {
        "id": "U3165WeoY_7z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Building function contain all evaluation techniques we used in this project\n",
        "def accuracy (y_test,y_pred):\n",
        "  cr = classification_report(y_test,y_pred)\n",
        "  acc = accuracy_score(y_test,y_pred)\n",
        "  print(cr)\n",
        "  return acc"
      ],
      "metadata": {
        "id": "vho-X4Vno-qB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Random Forest"
      ],
      "metadata": {
        "id": "i2k_1HduZ8qQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy(y_test,y_pred_RF)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Ptwc8WaYOfl",
        "outputId": "62e4a2af-d451-4933-bad0-7b5f715e9a79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99       390\n",
            "           1       1.00      1.00      1.00      2507\n",
            "\n",
            "    accuracy                           1.00      2897\n",
            "   macro avg       1.00      0.99      0.99      2897\n",
            "weighted avg       1.00      1.00      1.00      2897\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9968933379357956"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Naive Bayes"
      ],
      "metadata": {
        "id": "T6hjOffkaFki"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy(y_test,y_pred_NB)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w_7x5YaOZ5CQ",
        "outputId": "a5c5ed0e-1c71-4e97-dad6-63e62346e648"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.44      0.40      0.42       390\n",
            "           1       0.91      0.92      0.91      2507\n",
            "\n",
            "    accuracy                           0.85      2897\n",
            "   macro avg       0.67      0.66      0.66      2897\n",
            "weighted avg       0.84      0.85      0.85      2897\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8498446668967898"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Adaboost "
      ],
      "metadata": {
        "id": "HwBJPXTwaZAV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy(y_test,y_pred_Adaboost)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YxS0rp5OaVoS",
        "outputId": "4f51ee31-391b-4372-e94b-302ab3da1dd2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.84      0.88       390\n",
            "           1       0.98      0.99      0.98      2507\n",
            "\n",
            "    accuracy                           0.97      2897\n",
            "   macro avg       0.95      0.91      0.93      2897\n",
            "weighted avg       0.97      0.97      0.97      2897\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9678978253365551"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Final decision method 1"
      ],
      "metadata": {
        "id": "QlecRpQCE2R0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_models = {'RF':y_pred_RF,'NB':y_pred_NB,'Adaboost':y_pred_Adaboost}\n",
        "df = pd.DataFrame(all_models)\n",
        "Aggregator = df.sum(axis=1)\n",
        "final_decision = []\n",
        "for i in Aggregator:\n",
        "  if i >= 2:\n",
        "    final_decision.append(1)\n",
        "  else:\n",
        "    final_decision.append(0)\n",
        "final_decision"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TpPcNE_wQIBT",
        "outputId": "cb0789bf-f2d8-4431-b55b-0afad4d6a35d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " ...]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# def voting(x_train,y_train,x_test,RF,NB,Adaboost):\n",
        "#   model(x_train,y_train,x_test)\n",
        "#   voting = VotingClassifier(estimators=[('RF',RF),('NB',NB),('Adaboost',Adaboost)], voting = 'hard')\n",
        "#   voting.fit(x_train,y_train)\n",
        "#   final_decision = voting.predict(x_test)\n",
        "#   return final_decision"
      ],
      "metadata": {
        "id": "KKVzy5hRE7Np"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# final_decision = voting(x_train,y_train,x_test,RF,NB,Adaboost)\n",
        "# final_decision"
      ],
      "metadata": {
        "id": "E8TmvVbaE7KK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Final decision method 2"
      ],
      "metadata": {
        "id": "WOCU0i5fcoVj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_RF = RF.predict(x_train)\n",
        "y_NB = NB.predict(x_train)\n",
        "y_Adaboost = Adaboost.predict(x_train)\n",
        "X = accuracy(y_train,y_RF)\n",
        "Y = accuracy(y_train,y_Adaboost)\n",
        "Z = accuracy(y_train,y_NB)\n",
        "W_RF = X/(X+Y+Z)\n",
        "W_Adaboost = Y/(X+Y+Z)\n",
        "W_NB = Z/(X+Y+Z)\n",
        "Aggregated_output = y_pred_RF * W_RF + y_pred_NB * W_NB + y_pred_Adaboost * W_Adaboost\n",
        "print(Aggregated_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M6nZWgodhaHy",
        "outputId": "4be40071-42ca-4f81-b8af-326be75b7d58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00      1507\n",
            "           1       1.00      1.00      1.00     10080\n",
            "\n",
            "    accuracy                           1.00     11587\n",
            "   macro avg       1.00      1.00      1.00     11587\n",
            "weighted avg       1.00      1.00      1.00     11587\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.86      0.89      1507\n",
            "           1       0.98      0.99      0.98     10080\n",
            "\n",
            "    accuracy                           0.97     11587\n",
            "   macro avg       0.95      0.93      0.94     11587\n",
            "weighted avg       0.97      0.97      0.97     11587\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.45      0.42      0.44      1507\n",
            "           1       0.91      0.92      0.92     10080\n",
            "\n",
            "    accuracy                           0.86     11587\n",
            "   macro avg       0.68      0.67      0.68     11587\n",
            "weighted avg       0.85      0.86      0.86     11587\n",
            "\n",
            "[1.         1.         1.         ... 1.         1.         0.30314673]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_decision_2 = []\n",
        "for i in Aggregated_output:\n",
        "  if i > 0.5 :\n",
        "    final_decision_2.append(1)\n",
        "  else:\n",
        "    final_decision_2.append(0)"
      ],
      "metadata": {
        "id": "gbr8iCIphNaO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_decision_2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UtUfGQNhaxjH",
        "outputId": "95568902-2fe4-435e-8bd0-cf64134349ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " ...]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Comparision"
      ],
      "metadata": {
        "id": "4VOrZESeg3tv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Ensemble_vote = accuracy(y_test,final_decision)\n",
        "Ensemble_wieghted = accuracy(y_test,final_decision_2)\n",
        "acc_RF = accuracy(y_test,y_pred_RF)\n",
        "acc_NB = accuracy(y_test,y_pred_NB)\n",
        "acc_Adaboost = accuracy(y_test,y_pred_Adaboost)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JhNHV-JUfzPk",
        "outputId": "3707f785-8319-4649-fa8e-d44bd0e7d396"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.83      0.90       390\n",
            "           1       0.97      1.00      0.99      2507\n",
            "\n",
            "    accuracy                           0.97      2897\n",
            "   macro avg       0.97      0.91      0.94      2897\n",
            "weighted avg       0.97      0.97      0.97      2897\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.83      0.90       390\n",
            "           1       0.97      1.00      0.99      2507\n",
            "\n",
            "    accuracy                           0.97      2897\n",
            "   macro avg       0.97      0.91      0.94      2897\n",
            "weighted avg       0.97      0.97      0.97      2897\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99       390\n",
            "           1       1.00      1.00      1.00      2507\n",
            "\n",
            "    accuracy                           1.00      2897\n",
            "   macro avg       1.00      0.99      0.99      2897\n",
            "weighted avg       1.00      1.00      1.00      2897\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.44      0.40      0.42       390\n",
            "           1       0.91      0.92      0.91      2507\n",
            "\n",
            "    accuracy                           0.85      2897\n",
            "   macro avg       0.67      0.66      0.66      2897\n",
            "weighted avg       0.84      0.85      0.85      2897\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.84      0.88       390\n",
            "           1       0.98      0.99      0.98      2507\n",
            "\n",
            "    accuracy                           0.97      2897\n",
            "   macro avg       0.95      0.91      0.93      2897\n",
            "weighted avg       0.97      0.97      0.97      2897\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualization"
      ],
      "metadata": {
        "id": "nUTzCHR_gwEu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "from IPython.core.pylabtools import figsize\n",
        "figsize(10,7)\n",
        "sns.barplot(x=['RF','Adaboost','NB','Ensemble vote','Ensemble wieghted'], y = [acc_RF,acc_Adaboost,acc_NB,Ensemble_vote,Ensemble_wieghted],palette='dark:salmon_r')\n",
        "plt.ylim(0.8,1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        },
        "id": "fJJL0Vg2aD3G",
        "outputId": "14d5798e-c719-4c47-d646-039315fa1932"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.8, 1.0)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GAN"
      ],
      "metadata": {
        "id": "u7EqXdTV2DaN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Constant variables"
      ],
      "metadata": {
        "id": "Exh8f-HKFN0i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "num_channels = 12\n",
        "num_classes = 2\n",
        "latent_dim = 128"
      ],
      "metadata": {
        "id": "WkSAD9jrWNKd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare the training data\n"
      ],
      "metadata": {
        "id": "nhg-f4-cCdFt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_new = keras.utils.to_categorical(y_train, 2)\n",
        "dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train_new))\n",
        "dataset = dataset.shuffle(buffer_size=1024).batch(batch_size)\n",
        "\n",
        "print(f\"Shape of training images: {x_train.shape}\")\n",
        "print(f\"Shape of training labels: {y_train_new.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "js8oiNKVXEuf",
        "outputId": "86f1a7ce-92f3-4142-ebea-12fed73c5f24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of training images: (11587, 12)\n",
            "Shape of training labels: (11587, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generator_in_channels = latent_dim + num_classes\n",
        "discriminator_in_channels = num_channels + num_classes\n",
        "print(generator_in_channels, discriminator_in_channels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hhw_EBO7tn_E",
        "outputId": "bcf18f0c-374d-4585-becc-9183188ce08c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "130 14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building Generator and Discriminator models"
      ],
      "metadata": {
        "id": "8JV8r8ncHizJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the discriminator.\n",
        "discriminator = Sequential(\n",
        "    [\n",
        "        Dense(512,input_dim = discriminator_in_channels),\n",
        "        LeakyReLU(alpha=0.2),\n",
        "        Dense(512),\n",
        "        LeakyReLU(alpha=0.2),\n",
        "        Dropout(0.4),\n",
        "        Dense(512),\n",
        "        LeakyReLU(alpha=0.2),\n",
        "        Dropout(0.4),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ],\n",
        "    name=\"discriminator\"\n",
        ")\n",
        "\n",
        "# Create the generator.\n",
        "generator = Sequential(\n",
        "    [\n",
        "        Dense(256,input_dim = generator_in_channels),\n",
        "        LeakyReLU(alpha=0.2),\n",
        "        BatchNormalization(momentum=0.8),\n",
        "        Dense(512),\n",
        "        LeakyReLU(alpha=0.2),\n",
        "        BatchNormalization(momentum=0.8),\n",
        "        Dense(1024),\n",
        "        LeakyReLU(alpha=0.2),\n",
        "        BatchNormalization(momentum=0.8),\n",
        "        Dense(12)],\n",
        "    name=\"generator\"\n",
        ")"
      ],
      "metadata": {
        "id": "ypG4wJroWgZ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conditional GAN"
      ],
      "metadata": {
        "id": "66Dihw1aNw_q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ConditionalGAN(keras.Model):\n",
        "    def __init__(self, discriminator, generator, latent_dim):\n",
        "        super(ConditionalGAN, self).__init__()\n",
        "        self.discriminator = discriminator\n",
        "        self.generator = generator\n",
        "        self.latent_dim = latent_dim\n",
        "        self.gen_loss_tracker = keras.metrics.Mean(name=\"generator_loss\")\n",
        "        self.disc_loss_tracker = keras.metrics.Mean(name=\"discriminator_loss\")\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        return [self.gen_loss_tracker, self.disc_loss_tracker]\n",
        "\n",
        "    def compile(self, d_optimizer, g_optimizer, loss_fn):\n",
        "        super(ConditionalGAN, self).compile()\n",
        "        self.d_optimizer = d_optimizer\n",
        "        self.g_optimizer = g_optimizer\n",
        "        self.loss_fn = loss_fn\n",
        "\n",
        "    def train_step(self, data):\n",
        "        # Unpack the data.\n",
        "        real_tasks, one_hot_labels = data\n",
        "\n",
        "        # Add dummy dimensions to the labels so that they can be concatenated with the tasks. This is for the discriminator.\n",
        "        task_one_hot_labels = one_hot_labels[:, :, None, None]\n",
        "        task_one_hot_labels = tf.reshape(task_one_hot_labels, (-1, num_classes))\n",
        "\n",
        "\n",
        "        # Sample random points in the latent space and concatenate the labels. This is for the generator.\n",
        "        batch_size = tf.shape(real_tasks)[0]\n",
        "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
        "        random_vector_labels = tf.concat([random_latent_vectors, one_hot_labels], axis=1)\n",
        "\n",
        "        # Decode the noise (guided by labels) to fake tasks.\n",
        "        generated_tasks = self.generator(random_vector_labels)\n",
        "\n",
        "        # Combine them with real tasks. Note that we are concatenating the labels with these tasks here.\n",
        "        real_tasks = tf.cast(real_tasks, tf.float32)\n",
        "        fake_task_and_labels = tf.concat([generated_tasks, task_one_hot_labels], -1)\n",
        "        real_task_and_labels = tf.concat([real_tasks, task_one_hot_labels], -1)\n",
        "        combined_tasks = tf.concat([fake_task_and_labels, real_task_and_labels], axis=0)\n",
        "\n",
        "        # Assemble labels discriminating real from fake tasks.\n",
        "        labels = tf.concat([tf.ones((batch_size, 1)), tf.zeros((batch_size, 1))], axis=0)\n",
        "\n",
        "        # Train the discriminator.\n",
        "        with tf.GradientTape() as tape:\n",
        "            predictions = self.discriminator(combined_tasks)\n",
        "            d_loss = self.loss_fn(labels, predictions)\n",
        "        grads = tape.gradient(d_loss, self.discriminator.trainable_weights)\n",
        "        self.d_optimizer.apply_gradients(zip(grads, self.discriminator.trainable_weights))\n",
        "\n",
        "        # Sample random points in the latent space.\n",
        "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
        "        random_vector_labels = tf.concat([random_latent_vectors, one_hot_labels], axis=1)\n",
        "\n",
        "        # Assemble labels that say \"all real images\".\n",
        "        misleading_labels = tf.zeros((batch_size, 1))\n",
        "\n",
        "        # Train the generator (note that we should *not* update the weights of the discriminator)!\n",
        "        with tf.GradientTape() as tape:\n",
        "            fake_tasks = self.generator(random_vector_labels)\n",
        "            fake_task_and_labels = tf.concat([fake_tasks, task_one_hot_labels], -1)\n",
        "            predictions = self.discriminator(fake_task_and_labels)\n",
        "            g_loss = self.loss_fn(misleading_labels, predictions)\n",
        "        grads = tape.gradient(g_loss, self.generator.trainable_weights)\n",
        "        self.g_optimizer.apply_gradients(zip(grads, self.generator.trainable_weights))\n",
        "\n",
        "        # Monitor loss.\n",
        "        self.gen_loss_tracker.update_state(g_loss)\n",
        "        self.disc_loss_tracker.update_state(d_loss)\n",
        "        return {\n",
        "            \"g_loss\": self.gen_loss_tracker.result(),\n",
        "            \"d_loss\": self.disc_loss_tracker.result(),\n",
        "        }"
      ],
      "metadata": {
        "id": "ZOAqQrr-c74o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cond_gan = ConditionalGAN(\n",
        "    discriminator=discriminator, generator=generator, latent_dim=latent_dim\n",
        ")\n",
        "cond_gan.compile(\n",
        "    d_optimizer=keras.optimizers.Adam(learning_rate=0.0003),\n",
        "    g_optimizer=keras.optimizers.Adam(learning_rate=0.0003),\n",
        "    loss_fn=keras.losses.BinaryCrossentropy(),\n",
        ")\n",
        "\n",
        "cond_gan.fit(dataset, epochs=20)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pp0Tkmhf8g_Y",
        "outputId": "1dc196f7-476b-4f1a-d971-d090f68e8579"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "182/182 [==============================] - 9s 36ms/step - g_loss: 1.3895 - d_loss: 0.6644\n",
            "Epoch 2/20\n",
            "182/182 [==============================] - 7s 37ms/step - g_loss: 0.7756 - d_loss: 0.7241\n",
            "Epoch 3/20\n",
            "182/182 [==============================] - 7s 36ms/step - g_loss: 0.7446 - d_loss: 0.6976\n",
            "Epoch 4/20\n",
            "182/182 [==============================] - 7s 36ms/step - g_loss: 0.6853 - d_loss: 0.7063\n",
            "Epoch 5/20\n",
            "182/182 [==============================] - 7s 36ms/step - g_loss: 0.6917 - d_loss: 0.7122\n",
            "Epoch 6/20\n",
            "182/182 [==============================] - 7s 37ms/step - g_loss: 0.7326 - d_loss: 0.7177\n",
            "Epoch 7/20\n",
            "182/182 [==============================] - 7s 36ms/step - g_loss: 0.7273 - d_loss: 0.6952\n",
            "Epoch 8/20\n",
            "182/182 [==============================] - 7s 36ms/step - g_loss: 0.7183 - d_loss: 0.7016\n",
            "Epoch 9/20\n",
            "182/182 [==============================] - 7s 36ms/step - g_loss: 0.8398 - d_loss: 0.7296\n",
            "Epoch 10/20\n",
            "182/182 [==============================] - 7s 37ms/step - g_loss: 0.7943 - d_loss: 0.6948\n",
            "Epoch 11/20\n",
            "182/182 [==============================] - 7s 36ms/step - g_loss: 0.6353 - d_loss: 0.7087\n",
            "Epoch 12/20\n",
            "182/182 [==============================] - 7s 36ms/step - g_loss: 0.7537 - d_loss: 0.6882\n",
            "Epoch 13/20\n",
            "182/182 [==============================] - 7s 36ms/step - g_loss: 0.7285 - d_loss: 0.7132\n",
            "Epoch 14/20\n",
            "182/182 [==============================] - 7s 36ms/step - g_loss: 0.7900 - d_loss: 0.6864\n",
            "Epoch 15/20\n",
            "182/182 [==============================] - 9s 48ms/step - g_loss: 0.7339 - d_loss: 0.7005\n",
            "Epoch 16/20\n",
            "182/182 [==============================] - 7s 36ms/step - g_loss: 0.7218 - d_loss: 0.7207\n",
            "Epoch 17/20\n",
            "182/182 [==============================] - 7s 36ms/step - g_loss: 0.7126 - d_loss: 0.6970\n",
            "Epoch 18/20\n",
            "182/182 [==============================] - 7s 36ms/step - g_loss: 0.7311 - d_loss: 0.7094\n",
            "Epoch 19/20\n",
            "182/182 [==============================] - 7s 36ms/step - g_loss: 0.7284 - d_loss: 0.6886\n",
            "Epoch 20/20\n",
            "182/182 [==============================] - 7s 36ms/step - g_loss: 0.8776 - d_loss: 0.6778\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4367e13610>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generate fake task  via generator network"
      ],
      "metadata": {
        "id": "mHr1-Pi8Q13b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We first extract the trained generator from our Conditional GAN.\n",
        "trained_gen = cond_gan.generator\n",
        "\n",
        "# Choose the number of intermediate tasks that would be generated\n",
        "num_interpolation = 2000  # @param {type:\"integer\"}\n",
        "\n",
        "# Sample noise for the interpolation.\n",
        "interpolation_noise = tf.random.normal(shape=(1, latent_dim))\n",
        "interpolation_noise = tf.repeat(interpolation_noise, repeats=num_interpolation)\n",
        "interpolation_noise = tf.reshape(interpolation_noise, (num_interpolation, latent_dim))\n",
        "\n",
        "\n",
        "def interpolate_class(class1):\n",
        "    # Convert the start label to one-hot encoded vectors.\n",
        "    first_label = keras.utils.to_categorical([class1]*num_interpolation, num_classes)\n",
        "    \n",
        "    # Combine the noise and the labels and run inference with the generator.\n",
        "    noise_and_labels = tf.concat([interpolation_noise, first_label], 1)\n",
        "    fake = trained_gen.predict(noise_and_labels)\n",
        "    return fake\n",
        "\n",
        "\n",
        "class1 = 1 \n",
        "\n",
        "fake_tasks = interpolate_class(class1)"
      ],
      "metadata": {
        "id": "eTnH7t7rAVpM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mix fake task with the original test dataset\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "xDkyfrgRQUSz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_test_new = np.concatenate((x_test,fake_tasks),axis = 0)\n",
        "x_test_new"
      ],
      "metadata": {
        "id": "IqFrjTiiL4_Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5154bc53-9575-4383-9de2-bbfbdf3d48c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.91147787,  0.79765584,  0.62859103, ...,  0.5       ,\n",
              "         0.        ,  0.79999094],\n",
              "       [ 0.90047512,  0.6936453 ,  0.12188244, ...,  0.45714286,\n",
              "         0.        ,  0.67495598],\n",
              "       [ 0.96499125,  0.64613102,  0.35259348, ...,  0.7       ,\n",
              "         0.        ,  0.62497769],\n",
              "       ...,\n",
              "       [ 1.19679046,  0.72414821,  0.78746676, ..., -0.57519746,\n",
              "         0.47345996,  0.52010113],\n",
              "       [ 1.19679046,  0.72414821,  0.78746676, ..., -0.57519746,\n",
              "         0.47345996,  0.52010113],\n",
              "       [ 1.19679046,  0.72414821,  0.78746676, ..., -0.57519746,\n",
              "         0.47345996,  0.52010113]])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fake_task_label = np.zeros(num_interpolation)\n",
        "y_test_new = np.concatenate((y_test,fake_task_label),axis = 0)\n",
        "y_test_new"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQncGWMkUg2S",
        "outputId": "9ac57eaf-748c-4ca3-a82b-f8cda537bc70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1., 1., 1., ..., 0., 0., 0.])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train the machine learning models with new test set"
      ],
      "metadata": {
        "id": "4qpbubEURwyw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_RF_new, y_pred_NB_new, y_pred_Adaboost_new,RF_new,NB_new,Adaboost_new =  model(x_train,y_train,x_test_new)"
      ],
      "metadata": {
        "id": "DaU4FZ39Qqqq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc_RF_new = accuracy(y_test_new,y_pred_RF_new)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LuKb2-65T7_h",
        "outputId": "bc594642-bbf6-4771-bcb5-a12f0e8d8279"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      0.16      0.28      2390\n",
            "         1.0       0.56      1.00      0.71      2507\n",
            "\n",
            "    accuracy                           0.59      4897\n",
            "   macro avg       0.78      0.58      0.49      4897\n",
            "weighted avg       0.77      0.59      0.50      4897\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "acc_Adaboost_new = accuracy(y_test_new,y_pred_Adaboost_new)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DpWkd5RnV7QL",
        "outputId": "23b8b319-61ce-408b-fd37-37156fd798f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.95      0.23      0.37      2390\n",
            "         1.0       0.57      0.99      0.73      2507\n",
            "\n",
            "    accuracy                           0.62      4897\n",
            "   macro avg       0.76      0.61      0.55      4897\n",
            "weighted avg       0.76      0.62      0.55      4897\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "acc_NB_new = accuracy(y_test_new,y_pred_NB_new)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RCHjxTUPWFjc",
        "outputId": "717e04f8-3210-4405-84c0-bd6e4e8b38c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.44      0.07      0.12      2390\n",
            "         1.0       0.51      0.92      0.65      2507\n",
            "\n",
            "    accuracy                           0.50      4897\n",
            "   macro avg       0.48      0.49      0.39      4897\n",
            "weighted avg       0.48      0.50      0.39      4897\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "figsize(10,7)\n",
        "sns.barplot(x=['RF','Adaboost'], y = [acc_RF_new,acc_Adaboost_new],palette='dark:salmon_r')\n",
        "plt.title(\"Accuracy under mixed test dataset\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        },
        "id": "eYQKN8U4WMw2",
        "outputId": "5281def9-6818-4122-ab79-828ec5671127"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Accuracy under mixed test dataset')"
            ]
          },
          "metadata": {},
          "execution_count": 34
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cascade framework"
      ],
      "metadata": {
        "id": "Vk0NoZEAW2EG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y = keras.utils.to_categorical(y_test_new, 2)\n",
        "data = tf.concat([x_test_new,y],axis=1)\n",
        "new_prediction = cond_gan.discriminator.predict(data)\n",
        "new_prediction"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1HcjciIvWs9j",
        "outputId": "03614003-a49b-4b4b-da9b-39d945dfb083"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.5358621 ],\n",
              "       [0.50779533],\n",
              "       [0.52528095],\n",
              "       ...,\n",
              "       [0.79594505],\n",
              "       [0.79594505],\n",
              "       [0.79594505]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_prediction = np.round(new_prediction).astype(int)\n",
        "new_prediction"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XTPdCJs7YwTE",
        "outputId": "ce7586af-eb6c-4b69-d0a7-6250bd8e9b50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1],\n",
              "       [1],\n",
              "       [1],\n",
              "       ...,\n",
              "       [1],\n",
              "       [1],\n",
              "       [1]])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "idx = np.where(new_prediction == 1)[0]\n",
        "x_real_cascade = x_test_new[idx]\n",
        "y_real_discriminator = np.ones(x_real_cascade.shape[0])"
      ],
      "metadata": {
        "id": "chOA4m5Maikx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_RF_cascade, y_pred_NB_cascade, y_pred_Adaboost_cascade,RF_cascade,NB_cascade,Adaboost_cascade =  model(x_train,y_train,x_real_cascade)"
      ],
      "metadata": {
        "id": "vk84NtnraB8S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc_RF_cascade = accuracy(y_real_discriminator,y_pred_RF_cascade)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M7hCGlxRaYts",
        "outputId": "a01546ab-757b-46b5-a552-8b519e134739"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.00      0.00      0.00         0\n",
            "         1.0       1.00      0.95      0.98      3378\n",
            "\n",
            "    accuracy                           0.95      3378\n",
            "   macro avg       0.50      0.48      0.49      3378\n",
            "weighted avg       1.00      0.95      0.98      3378\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "acc_Adaboost_cascade = accuracy(y_real_discriminator,y_pred_Adaboost_cascade)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xprJUns1bO_i",
        "outputId": "f21f2031-bba7-4bff-b769-5092d1c36da1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.00      0.00      0.00         0\n",
            "         1.0       1.00      0.89      0.94      3378\n",
            "\n",
            "    accuracy                           0.89      3378\n",
            "   macro avg       0.50      0.45      0.47      3378\n",
            "weighted avg       1.00      0.89      0.94      3378\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "figsize(10,7)\n",
        "sns.barplot(x=['RF-based Cascade','Adaboost-based Cascade'], y = [acc_RF_cascade,acc_Adaboost_cascade],palette='dark:salmon_r')\n",
        "plt.title(\"Accuracy under mixed test dataset\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        },
        "id": "r3GmHoumgI8g",
        "outputId": "7bc4b57a-e861-4a6a-c7bd-f2c0e183bec2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Accuracy under mixed test dataset')"
            ]
          },
          "metadata": {},
          "execution_count": 41
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}